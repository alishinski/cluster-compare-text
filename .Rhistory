ggplot(n_users_df[1:75, ], aes(Var1, Freq)) +
geom_line() +
ylab("N Users") +
xlab("N Tweets") +
ggtitle("Number of Users per Number of Tweets")
ggplot(n_users_df[1:75, ], aes(Var1, Freq)) +
geom_path() +
ylab("N Users") +
xlab("N Tweets") +
ggtitle("Number of Users per Number of Tweets")
ggplot(n_users_df[1:75, ], aes(Var1, Freq)) +
geom_point() +
ylab("N Users") +
xlab("N Tweets") +
ggtitle("Number of Users per Number of Tweets")
user_dist <- round(user_dist, digits = 3)
user_dist
user_dist_df <- as.data.frame(user_dist_df)
user_dist_df <- as.data.frame(user_dist)
str(user_dist_df)
user_dist_df
ggplot(user_dist_df, aes(row.names(user_dist_df), user_dist)) +
geom_point()
user_dist_df
user_num
qplot(user_num)
user_num <- as.data.frame(user_num)
user_num
ggplot(user_dist_df, aes(row.names(user_dist_df), user_dist)) +
geom_point()
user_dist_df
user_dist_df
ggplot(user_dist_df, aes(user_dist)) +
geom_point()
user_dist_df
user_dist_df <- cbind(row.names(user_dist_df))
user_dist_df
user_dist_df <- cbind(row.names(user_dist_df), user_dist_df)
user_dist_df
user_dist <- user_num / sum(user_num) * 100
user_dist <- round(user_dist, digits = 3)
user_dist_df <- as.data.frame(user_dist)
user_dist_df <- cbind(row.names(user_dist_df), user_dist_df)
user_dist_df
colnames(user_dist_df) <- c("n", "user_num")
ggplot(user_dist_df, aes(n, user_num)) +
geom_point()
n_users
ggplot(n_users_df[1:75, ], aes(Var1, Freq)) +
geom_point() +
ylab("N Users") +
xlab("N Tweets") +
ggtitle("Number of Users per Number of Tweets")
ggsave("nusers_ntweets.pdf")
user_dist
plot(user_dist)
qplot(user_dist)
user_dist_df
user_num
user_num <- cbind(row.names(user_num), user_num)
user_num_df <- cbind(row.names(user_num), user_num)
user_num_df
user_num <- colSums(table(sum))
user_num <- as.data.frame(user_num)
user_num_df <- cbind(row.names(user_num), user_num)
user_num_df
ggplot(user_num_df, aes(row.names(user_num), user_num)) +
geom_point()
ggplot(user_num_df, aes(N_tags, N_users)) +
geom_point()
user_num <- colSums(table(sum))
user_num <- as.data.frame(user_num)
user_num_df <- cbind(row.names(user_num), user_num)
names(user_num_df) <- c("N_tags", "N_users")
ggplot(user_num_df, aes(N_tags, N_users)) +
geom_point()
ggplot(user_num_df, aes(order(N_tags), N_users)) +
geom_point()
ggplot(user_num_df, aes(sort(N_tags), N_users)) +
geom_point()
user_num
user_dist
write.csv(user_dist, "user_dist.csv")
n_users
write.csv(n_users, "n_tweets.csv")
n_users
n_users / sum(n_users)
round(n_users / sum(n_users), 3)
round(n_users / sum(n_users), 4)
write.csv(round(n_users / sum(n_users), 4), "n_tweets.csv")
data <- read.csv("~/Dropbox/Current Research/scip/Scientific Practices Josh/generality/generality_consensus_coding_3.csv", stringsAsFactors = FALSE)
data
write.csv(data, "data.csv")
str(data)
rownames(data) <- NULL
str(data)
write.csv(data, "data.csv")
data <- data[, -6]
write.csv(data, "data.csv")
data <- as.character(data$genAspecB)
str(data)
#-------------------------------------------------------
# 1. Setting working directory, loading packages, and loading files
#-------------------------------------------------------
# Clearing environment
rm(list = ls(all = TRUE))
# Setting working directory
setwd("~/Dropbox/statistics/cluster-compare-text/")
# Loading packages - if packages are not already installed, call install.packages() first, e.g. for dplyr install.packages("dplyr")
library(dplyr)
library(tidyr)
library(SnowballC)
library(tm)
library(lsa)
library(cluster)
library(ggplot2)
library(wordcloud)
# Loading data frame
all <- read.csv("scip_data.csv")
# Selecting columns of dataframe by question topic
aud <- select(all, audience1, grade, teacher, ID, time)
aud2 <- select(all, audience2, grade, teacher, ID, time)
gen <- select(all, generality, grade, teacher, ID, time)
evid <- select(all, evidence, grade, teacher, ID, time)
purp <- select(all, purpose, grade, teacher, ID, time)
crit <- select(all, criteria, grade, teacher, ID, time)
# Selecting data frame for analysis
doc_vec <- aud$audience1
#-------------------------------------------------------
# 2. Variables to modify
#-------------------------------------------------------
# Number of clusters
n_clusters <- 5
# Stopwords
#stopwords <- TRUE
# Custom stopwords
custom_stopwords <- c("thatïûªs") # need to fix - not sure why apostrophes aren't being encoded properly - try to save data again?
# Sparseness of term document matrices (from 0.00 to 1.00)
sparseness <- .999 ## is there a way to improve this to make it more intuitive? currently, lower sparseness leads to more terms
# Weighting of terms in term document matrices (weightTF, weightTfIdf, or weightBin)
# weighting <-
# Normalization of terms in term document matrices
# normalization <- TRUE
# Stem document
# stem <- TRUE
# Distance metric
# distance <-
# Type of plot (usin scaled or un-scaled cosines)
# plot_type <-
# Group factor
# group <-
#-------------------------------------------------------
# 3. Creating corpora and term document matrices
#-------------------------------------------------------
# Creating a list of groups of corpora for each group of vectors
# Modified stemCompletion function, as stemCompletion was not working
stemCompletion2 <- function(x, dictionary) {
x <- unlist(strsplit(as.character(x), " "))
x <- x[x != ""]
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
}
# Processing files
myCorpus <- Corpus(VectorSource(doc_vec))
myCorpus <- tm_map(myCorpus, content_transformer(tolower), mc.cores = 1)
myCorpus <- tm_map(myCorpus, removePunctuation, mc.cores = 1)
myCorpus <- tm_map(myCorpus, removeNumbers, mc.cores = 1)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"), mc.cores = 1)
myCorpus <- tm_map(myCorpus, removeWords, custom_stopwords, mc.cores=1)
myCorpus_copy <- myCorpus
myCorpus <- tm_map(myCorpus, stemDocument, mc.cores = 1)
myCorpus <- tm_map(myCorpus, stemCompletion2, myCorpus_copy)
myCorpus <- tm_map(myCorpus, stripWhitespace, mc.cores = 1)
myCorpus <- tm_map(myCorpus, PlainTextDocument)
print(paste("Processed ", length(doc_vec), " documents", sep = ""))
#-------------------------------------------------------
# 4. For overall term document matrix
#-------------------------------------------------------
# Creating a term document matrix from the corpus ## need to fix documents with no text (or earlier)
TDM <- TermDocumentMatrix(myCorpus, control = list(weighting = function(x) weightSMART(x, spec = "nnn")))
# Removing sparse terms
TDM_common <- removeSparseTerms(TDM, sparseness)
#-------------------------------------------------------
# 5. For group term document matrices
#-------------------------------------------------------
# Name documents ## Specific to scip data
for (i in 1:length(myCorpus)){
meta(myCorpus[[i]], "teacher") <- aud$teacher[i]
meta(myCorpus[[i]], "grade") <- aud$grade[i]
meta(myCorpus[[i]], "ID") <- aud$ID[i]
meta(myCorpus[[i]], "time") <- aud$time[i]
}
# Filter term document matrices by group ## need to fix - loop these!
# By teacher
index_j <- tm_index(myCorpus, function(x) meta(x, "teacher") == "j")
index_paul <- tm_index(myCorpus, function(x) meta(x, "teacher") == "paul")
index_cathy <- tm_index(myCorpus, function(x) meta(x, "teacher") == "cathy")
index_julie <- tm_index(myCorpus, function(x) meta(x, "teacher") == "julie")
# By time
index_1 <- tm_index(myCorpus, function(x) meta(x, "time") == 1)
index_2 <- tm_index(myCorpus, function(x) meta(x, "time") == 2)
index_3 <- tm_index(myCorpus, function(x) meta(x, "time") == 3)
index_4 <- tm_index(myCorpus, function(x) meta(x, "time") == 4)
index_5 <- tm_index(myCorpus, function(x) meta(x, "time") == 5)
index_6 <- tm_index(myCorpus, function(x) meta(x, "time") == 6)
# By grade
index_grade5 <- tm_index(myCorpus, function(x) meta(x, "grade") == 5)
index_grade6 <- tm_index(myCorpus, function(x) meta(x, "grade") == 6)
# By id # Need to fix
index_MC <- tm_index(myCorpus, function(x) meta(x, "ID") == 301120)
index_AD <- tm_index(myCorpus, function(x) meta(x, "ID") == 301181)
index_DN <- tm_index(myCorpus, function(x) meta(x, "ID") == 301134)
index_JS <- tm_index(myCorpus, function(x) meta(x, "ID") == 301142)
index_KH <- tm_index(myCorpus, function(x) meta(x, "ID") == 301212)
# Saving documents based on groups to a list ## need to fix when looped
doc_list <- list(index_j, index_paul, index_cathy, index_julie)
#-------------------------------------------------------
# 6. Preparing data for clustering
#-------------------------------------------------------
# Removing outliers
# Creates booleans for outliers
doc_len_M <- mean(sort(colSums(as.matrix(TDM_common))))
doc_len_SD <- sd(sort(colSums(as.matrix(TDM_common))))
plusCI <- doc_len_M + 1.65*(doc_len_SD) # need to change this
minusCI <- doc_len_M - 1.65*(doc_len_SD) # need to change this
# Removes outliers ## need to fix - not a valid method
plusCI_bool <- colSums(as.matrix(TDM_common)) > plusCI
minusCI_bool <- colSums(as.matrix(TDM_common)) < minusCI
print(sum(plusCI_bool))
print(sum(minusCI_bool))
adjminusCI_bool <- colSums(as.matrix(TDM_common)) == 0 # need to fix - change this
print(sum(adjminusCI_bool))
doc_outliers <- plusCI_bool + minusCI_bool + adjminusCI_bool
# Creates initial matrix which needs to have deviation vectors calculated
mat <- as.matrix(TDM_common)
# Filters initial matrix by boolean vectors to remove document outliers
TDM <- TDM_common[, !doc_outliers]
# mat <- mat[, !doc_outliers]
# Filters matrix by boolean vectors to remove term outliers resulting from removing document outliers
term_outliers <- rowSums(as.matrix(TDM)) == 0
# mat <- mat[!term_outliers, ]
TDM <- TDM[!term_outliers, ]
# Finds freq terms for use in deviation vectors
freq_terms <- rowSums(as.matrix(TDM))
# Weights by deviation vectors
mat <- as.matrix(TDM)
for (i in seq(ncol(mat))){
mat[, i] <- mat[, i] - freq_terms / nrow(mat)
#adj_mat[i, ] <- adj_mat[i, ] / sum(adj_mat[i, ]) # weights words by proportion in the document ## need to fix -- change
}
# sort(freq_terms / nrow(TDM)) ## need to fix
# mat <- t(mat) # need to fix - move into for loop below
# DTM <- t(TDM) ## need to fix
mat <- as.matrix(TDM_common)
mat
str(mat)
str(mat)
TDM_cleaned <- TDM_common[, !doc_outliers]
str(TDM_cleaned)
str(TDM)
TDM
TDM_cleaned <- TDM_common[, !doc_outliers]
str(TDM_cleaned)
str(TDM_common)
TDM_cleaned
TDM_common
term_outliers <- rowSums(as.matrix(TDM)) == 0
TDM_cleaned <- TDM_cleaned[!term_outliers, ]
TDM_cleaned
TDM_cleaned <- TDM_cleaned[!term_outliers, ]
TDM_cleaned
term_outliers
sum(term_outliers)
term_outliers <- rowSums(as.matrix(TDM_cleaned)) == 0
sum(term_outliers)
TDM_cleaned <- TDM_cleaned[!term_outliers, ]
TDM_cleaned
freq_terms <- rowSums(as.matrix(TDM_cleaned))
freq_terms
mat <- as.matrix(TDM_cleaned)
for (i in seq(ncol(mat))){
mat[, i] <- mat[, i] - freq_terms / nrow(mat)
#adj_mat[i, ] <- adj_mat[i, ] / sum(adj_mat[i, ]) # weights words by proportion in the document ## need to fix -- change
}
mat_t <- t(mat)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
table(kfit$cluster)
table(kfit$cluster)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
set.seed(06152015)
# Fits kmeans algorithm
mat_t <- t(mat)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
set.seed(06152015)
# Fits kmeans algorithm
mat_t <- t(mat)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
set.seed(06152015)
# Fits kmeans algorithm
mat_t <- t(mat)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
set.seed(06152015)
# Fits kmeans algorithm
mat_t <- t(mat)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
set.seed(06152015)
# Fits kmeans algorithm
mat_t <- t(mat)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
set.seed(06142015)
# Fits kmeans algorithm
mat_t <- t(mat)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
set.seed(06132015)
# Fits kmeans algorithm
mat_t <- t(mat)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
set.seed(06132015)
# Fits kmeans algorithm
mat_t <- t(mat)
kfit <- kmeans(mat_t, centers = n_clusters) # need to fix - find a way to stablize this - too random
# kfit <- kmeans(adj_mat, centers = n_clusters, nstart = 25, iter.max = 1000) ## need to fix this doesn't help
table(kfit$cluster)
clusters <- list()
# unadj_clusters <- list()
for (i in seq(n_clusters)){
clusters[[i]] <- mat_t[, kfit$cluster == i]
# unadj_clusters[[i]] <- rowSums(as.matrix(clusters[[i]])) # not sure I need this
clusters[[i]] <- rowSums(as.matrix(clusters[[i]])) / table(kfit$cluster)[i]
}
clusters[[1]] <- TDM_common[, kfit$cluster == 1]
clusters[[2]] <- TDM_common[, kfit$cluster == 2]
clusters[[3]] <- TDM_common[, kfit$cluster == 3]
clusters[[4]] <- TDM_common[, kfit$cluster == 4]
clusters[[5]] <- TDM_common[, kfit$cluster == 5]
clusters[[1]]
clusters[[2]]
clusters[[3]]
clusters[[4]]
clusters[[5]]
clusters <- list()
# unadj_clusters <- list()
for (i in seq(n_clusters)){
clusters[[i]] <- mat_t[, kfit$cluster == i]
# unadj_clusters[[i]] <- rowSums(as.matrix(clusters[[i]])) # not sure I need this
clusters[[i]] <- rowSums(as.matrix(clusters[[i]])) / table(kfit$cluster)[i]
}# mat <- t(mat) # need to fix - move into for loop below
DTM <- t(TDM)
clusters[[1]] <- TDM_cleaned[, kfit$cluster == 1]
clusters[[2]] <- TDM_cleaned[, kfit$cluster == 2]
clusters[[3]] <- TDM_cleaned[, kfit$cluster == 3]
clusters[[4]] <- TDM_cleaned[, kfit$cluster == 4]
clusters[[5]] <- TDM_cleaned[, kfit$cluster == 5]
clusters[[1]]
clusters[[2]]
clusters[[3]]
clusters[[4]]
clusters[[5]]
# Creating an ordered list of clusters
ordered_clusters <- list()
clusters_df <- matrix(nrow = 10, ncol = n_clusters)
for (i in seq(length(clusters))){
ordered_clusters[[i]] <- sort(clusters[[i]], decreasing = TRUE)
clusters_df[, i] <- names(ordered_clusters[[i]][1:10])
}
clusters_df <- as.data.frame(clusters_df)
colnames(clusters_df) <- paste("Cluster ", c(seq(n_clusters)), sep="")
### Creating an adjusted (by relevance) ordered list of clusters ## need to fix - this is not working (I think because of freq_terms)
str(clusters)
adjordered_clusters <- list()
adjclusters_df <- matrix(nrow = 10, ncol = n_clusters)
for (i in seq(length(clusters))){
adjordered_clusters[[i]] <- clusters[[i]] - freq_terms[[1]] / nrow(mat)
adjordered_clusters[[i]] <- sort(adjordered_clusters[[i]], decreasing = TRUE)
adjclusters_df[, i] <- names(my_list[[i]][1:10])
}
adjclusters_df <- as.data.frame(adjclusters_df)
colnames(adjclusters_df) <- paste("Cluster ", c(seq(n_clusters)), sep="")
# Creating an ordered list of clusters
ordered_clusters <- list()
clusters_df <- matrix(nrow = 10, ncol = n_clusters)
for (i in seq(length(clusters))){
ordered_clusters[[i]] <- sort(clusters[[i]], decreasing = TRUE)
clusters_df[, i] <- names(ordered_clusters[[i]][1:10])
}
clusters_df <- as.data.frame(clusters_df)
colnames(clusters_df) <- paste("Cluster ", c(seq(n_clusters)), sep="")
# Creating an ordered list of clusters
ordered_clusters <- list()
clusters_df <- matrix(nrow = 10, ncol = n_clusters)
for (i in seq(length(clusters))){
ordered_clusters[[i]] <- sort(clusters[[i]], decreasing = TRUE)
clusters_df[, i] <- names(ordered_clusters[[i]][1:10])
}
clusters_df <- as.data.frame(clusters_df)
colnames(clusters_df) <- paste("Cluster ", c(seq(n_clusters)), sep="")
traceback()
length(clusters)
ordered_clusters1 <- sort(clusters[[1]])
clusters[[1]]
ordered_clusters <- list()
clusters_df <- matrix(nrow = 10, ncol = n_clusters)
length(clusters)
for (i in seq(length(clusters))){
ordered_clusters[[i]] <- sort(as.matrix(clusters[[i]]), decreasing = TRUE)
clusters_df[, i] <- names(ordered_clusters[[i]][1:10])
}
ordered_clusters1 <- sort(clusters[[1]])
clusters[[1]]
clusters_df <- as.data.frame(clusters_df)
colnames(clusters_df) <- paste("Cluster ", c(seq(n_clusters)), sep="")
ordered_clusters1 <- sort(clusters[[1]])
clusters_df <- matrix(nrow = 10, ncol = n_clusters)
length(clusters)
for (i in seq(length(clusters))){
ordered_clusters[[i]] <- sort(as.matrix(clusters[[i]]), decreasing = TRUE)
clusters_df[, i] <- names(ordered_clusters[[i]][1:10])
}
ordered_clusters1 <- sort(clusters[[1]])
ordered_clusters1 <- sort(as.matrix(clusters[[1]]))
ordered_clusters1
str(clusters[[1]])
str(as.matrix(clusters[[1]]))
str(as.matrix(clusters[[1]]))
clusters_df <- as.data.frame(clusters_df)
str(as.matrix(clusters[[1]]))
sort(as.matrix(clusters[[1]]))
str(as.matrix(clusters[[1]]))
x <- (as.matrix(clusters[[1]]))
x
str(x)
sort(x)
str(x)
str(x)
x
x[1:10, 1:10]
str(x)
x[1:10, 1:10]
rowSums(x)
ordered_clusters <- list()
clusters_df <- matrix(nrow = 10, ncol = n_clusters)
length(clusters)
for (i in seq(length(clusters))){
ordered_clusters[[i]] <- sort(rowSums(as.matrix(clusters[[i]])), decreasing = TRUE)
#clusters_df[, i] <- names(ordered_clusters[[i]][1:10])
}
str(ordered_clusters)
ordered_clusters[[1]]
ordered_clusters <- list()
clusters_df <- matrix(nrow = 10, ncol = n_clusters)
length(clusters)
for (i in seq(length(clusters))){
ordered_clusters[[i]] <- sort(rowSums(as.matrix(clusters[[i]])), decreasing = TRUE)
clusters_df[, i] <- names(ordered_clusters[[i]][1:10])
}
ordered_clusters[[2]]
ordered_clusters[[3]]
clusters_df
clusters_df <- as.data.frame(clusters_df)
colnames(clusters_df) <- paste("Cluster ", c(seq(n_clusters)), sep="")
clusters_df
adjordered_clusters <- list()
adjclusters_df <- matrix(nrow = 10, ncol = n_clusters)
for (i in seq(length(clusters))){
adjordered_clusters[[i]] <- sort(rowSums(as.matrix(clusters[[i]])), decreasing = TRUE)
adjordered_clusters[[i]] <- adjordered_clusters[[i]] - freq_terms / nrow(mat)
adhclusters_df[, i] <- names(adjordered_clusters[[i]][1:10])
}
adjordered_clusters <- list()
adjclusters_df <- matrix(nrow = 10, ncol = n_clusters)
for (i in seq(length(clusters))){
adjordered_clusters[[i]] <- sort(rowSums(as.matrix(clusters[[i]])), decreasing = TRUE)
adjordered_clusters[[i]] <- adjordered_clusters[[i]] - freq_terms / nrow(mat)
adjclusters_df[, i] <- names(adjordered_clusters[[i]][1:10])
}
adjclusters_df <- as.data.frame(adjclusters_df)
colnames(adjclusters_df) <- paste("Cluster ", c(seq(n_clusters)), sep="")
adjclusters_df
clusters_df
